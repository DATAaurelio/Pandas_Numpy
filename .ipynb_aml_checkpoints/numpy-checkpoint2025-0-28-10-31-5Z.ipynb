{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1737449612874
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a3 = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,21,35]])\n",
        "a3"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "array([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12],\n       [13, 21, 35]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1737449613188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "av = np.empty([4,3])\n",
        "av"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "array([[ 3.00909377e-316,  0.00000000e+000,  3.08962726e-316],\n       [ 8.29886606e-022,  6.92082230e-310,  3.09012844e-316],\n       [-3.47374072e-112,  6.92082230e-310,  3.08734587e-316],\n       [ 7.52250814e-223,  6.92082229e-310,  2.83882847e-316]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1737449613437
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "az = np.zeros([3,5])\n",
        "az"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "array([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1737449613741
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ao = np.ones([3,5])\n",
        "ao"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "array([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1737449614032
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "af = np.full([3,5],9)\n",
        "af"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "array([[9, 9, 9, 9, 9],\n       [9, 9, 9, 9, 9],\n       [9, 9, 9, 9, 9]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1737449614418
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai = np.identity(5)\n",
        "ai"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "array([[1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1737449614700
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ar = np.arange(1,5)\n",
        "ar\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "array([1, 2, 3, 4])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1737449614991
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "al = np.linspace(1,100,20)\n",
        "al"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "array([  1.        ,   6.21052632,  11.42105263,  16.63157895,\n        21.84210526,  27.05263158,  32.26315789,  37.47368421,\n        42.68421053,  47.89473684,  53.10526316,  58.31578947,\n        63.52631579,  68.73684211,  73.94736842,  79.15789474,\n        84.36842105,  89.57894737,  94.78947368, 100.        ])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1737449615422
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aran = np.random.random([2,3])\n",
        "aran"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "array([[0.70732601, 0.03905107, 0.03079768],\n       [0.50279429, 0.37127704, 0.79643432]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1737449615743
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aran.ndim"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "2"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1737449616026
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aran.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "(2, 3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1737449616432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aran.dtype"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "dtype('float64')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1737449616764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "at = np.array(['Hola','mundo'])\n",
        "at.dtype"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "dtype('<U5')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1737449617123
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.info(al.astype)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "a.astype(dtype, order='K', casting='unsafe', subok=True, copy=True)\n\nCopy of the array, cast to a specified type.\n\nParameters\n----------\ndtype : str or dtype\n    Typecode or data-type to which the array is cast.\norder : {'C', 'F', 'A', 'K'}, optional\n    Controls the memory layout order of the result.\n    'C' means C order, 'F' means Fortran order, 'A'\n    means 'F' order if all the arrays are Fortran contiguous,\n    'C' order otherwise, and 'K' means as close to the\n    order the array elements appear in memory as possible.\n    Default is 'K'.\ncasting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n    Controls what kind of data casting may occur. Defaults to 'unsafe'\n    for backwards compatibility.\n\n      * 'no' means the data types should not be cast at all.\n      * 'equiv' means only byte-order changes are allowed.\n      * 'safe' means only casts which can preserve values are allowed.\n      * 'same_kind' means only safe casts or casts within a kind,\n        like float64 to float32, are allowed.\n      * 'unsafe' means any data conversions may be done.\nsubok : bool, optional\n    If True, then sub-classes will be passed-through (default), otherwise\n    the returned array will be forced to be a base-class array.\ncopy : bool, optional\n    By default, astype always returns a newly allocated array. If this\n    is set to false, and the `dtype`, `order`, and `subok`\n    requirements are satisfied, the input array is returned instead\n    of a copy.\n\nReturns\n-------\narr_t : ndarray\n    Unless `copy` is False and the other conditions for returning the input\n    array are satisfied (see description for `copy` input parameter), `arr_t`\n    is a new array of the same shape as the input array, with dtype, order\n    given by `dtype`, `order`.\n\nNotes\n-----\n.. versionchanged:: 1.17.0\n   Casting between a simple data type and a structured one is possible only\n   for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n   casting from multiple fields is not.\n\n.. versionchanged:: 1.9.0\n   Casting from numeric to string types in 'safe' casting mode requires\n   that the string dtype length is long enough to store the max\n   integer/float value converted.\n\nRaises\n------\nComplexWarning\n    When casting from complex to float or int. To avoid this,\n    one should use ``a.real.astype(t)``.\n\nExamples\n--------\n>>> x = np.array([1, 2, 2.5])\n>>> x\narray([1. ,  2. ,  2.5])\n\n>>> x.astype(int)\narray([1, 2, 2])\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1737449617449
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "al.astype('i')\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "array([  1,   6,  11,  16,  21,  27,  32,  37,  42,  47,  53,  58,  63,\n        68,  73,  79,  84,  89,  94, 100], dtype=int32)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1737449617769
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sort(al)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "array([  1.        ,   6.21052632,  11.42105263,  16.63157895,\n        21.84210526,  27.05263158,  32.26315789,  37.47368421,\n        42.68421053,  47.89473684,  53.10526316,  58.31578947,\n        63.52631579,  68.73684211,  73.94736842,  79.15789474,\n        84.36842105,  89.57894737,  94.78947368, 100.        ])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1737449618107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aran"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "array([[0.70732601, 0.03905107, 0.03079768],\n       [0.50279429, 0.37127704, 0.79643432]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1737449618443
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sort(aran,1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "array([[0.03079768, 0.03905107, 0.70732601],\n       [0.37127704, 0.50279429, 0.79643432]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1737449618804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sort(aran,axis=1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "array([[0.03079768, 0.03905107, 0.70732601],\n       [0.37127704, 0.50279429, 0.79643432]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1737449619133
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([2,3,4,5,0,6,1,5,4,-3])"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1737449619447
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(arr)\n",
        "np.max(arr)\n",
        "np.mean(arr)\n",
        "np.median(arr)\n",
        "np.absolute(arr)\n",
        "np.abs(arr)\n",
        "np.cumsum(arr)\n",
        "np.unique(arr)\n",
        "np.exp(arr)\n",
        "np.prod(arr)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1737449619781
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.NAN"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "nan"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1737449620112
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in arr:\n",
        "    print(x)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2\n3\n4\n5\n0\n6\n1\n5\n4\n-3\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1737449620457
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(arr)):\n",
        "    print(i, arr[i])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0 2\n1 3\n2 4\n3 5\n4 0\n5 6\n6 1\n7 5\n8 4\n9 -3\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1737449620743
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in aran:\n",
        "    for y in x:\n",
        "        print(y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.7073260066176629\n0.03905106698383942\n0.030797680338658928\n0.5027942938119725\n0.37127703615625285\n0.7964343206318288\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1737449621506
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a3"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "array([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12],\n       [13, 21, 35]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1737449621747
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in a3:\n",
        "    for y in x:\n",
        "        for z in y:\n",
        "            print(z)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'numpy.int64' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m a3:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;28mprint\u001b[39m(z)\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1737449622035
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.info(np.nditer)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737449622278
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in np.nditer(a3):\n",
        "    print(x)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737449622299
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.info(np.ndenumerate)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737449622318
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pos, x in np.ndenumerate(a3):\n",
        "    print(pos, x)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1737449622342
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.info(np.where)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " where()\n\nwhere(condition, [x, y], /)\n\nReturn elements chosen from `x` or `y` depending on `condition`.\n\n.. note::\n    When only `condition` is provided, this function is a shorthand for\n    ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n    preferred, as it behaves correctly for subclasses. The rest of this\n    documentation covers only the case where all three arguments are\n    provided.\n\nParameters\n----------\ncondition : array_like, bool\n    Where True, yield `x`, otherwise yield `y`.\nx, y : array_like\n    Values from which to choose. `x`, `y` and `condition` need to be\n    broadcastable to some shape.\n\nReturns\n-------\nout : ndarray\n    An array with elements from `x` where `condition` is True, and elements\n    from `y` elsewhere.\n\nSee Also\n--------\nchoose\nnonzero : The function that is called when x and y are omitted\n\nNotes\n-----\nIf all the arrays are 1-D, `where` is equivalent to::\n\n    [xv if c else yv\n     for c, xv, yv in zip(condition, x, y)]\n\nExamples\n--------\n>>> a = np.arange(10)\n>>> a\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> np.where(a < 5, a, 10*a)\narray([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n\nThis can be used on multidimensional arrays too:\n\n>>> np.where([[True, False], [True, True]],\n...          [[1, 2], [3, 4]],\n...          [[9, 8], [7, 6]])\narray([[1, 8],\n       [3, 4]])\n\nThe shapes of x, y, and the condition are broadcast together:\n\n>>> x, y = np.ogrid[:3, :4]\n>>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\narray([[10,  0,  0,  0],\n       [10, 11,  1,  1],\n       [10, 11, 12,  2]])\n\n>>> a = np.array([[0, 1, 2],\n...               [0, 2, 4],\n...               [0, 3, 6]])\n>>> np.where(a < 4, a, -1)  # -1 is broadcast\narray([[ 0,  1,  2],\n       [ 0,  2, -1],\n       [ 0,  3, -1]])\n"
        }
      ],
      "execution_count": 58,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(a3 < 5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "(array([0, 0, 0, 1]), array([0, 1, 2, 0]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "a3"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 73,
          "data": {
            "text/plain": "array([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9],\n       [10, 11, 12],\n       [13, 21, 35]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 73,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "a3[a3>1]\n",
        "a3[:2]\n",
        "a3[:2,1:]\n",
        "a3[(a3 >1) & (a3 % 2 == 0)]\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 78,
          "data": {
            "text/plain": "array([ 2,  4,  6,  8, 10, 12])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 78,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "arr2 = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "\n",
        "arr = np.concatenate((arr1, arr2), axis=1)\n",
        "arr"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 84,
          "data": {
            "text/plain": "array([[1, 2, 3, 1, 2, 3],\n       [4, 5, 6, 4, 5, 6],\n       [7, 8, 9, 7, 8, 9]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 84,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "arrs = np.stack((arr1, arr2), axis=1)\n",
        "arr"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 86,
          "data": {
            "text/plain": "array([[1, 2, 3, 1, 2, 3],\n       [4, 5, 6, 4, 5, 6],\n       [7, 8, 9, 7, 8, 9]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 86,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "arrs = np.stack((arr1, arr2), axis=0)\n",
        "arrs"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 89,
          "data": {
            "text/plain": "array([[[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]],\n\n       [[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 89,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 90,
          "data": {
            "text/plain": "array([[1, 2, 3, 1, 2, 3],\n       [4, 5, 6, 4, 5, 6],\n       [7, 8, 9, 7, 8, 9]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 90,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "splitted = np.array_split(arr, 3)\n",
        "splitted\n",
        "for s in splitted:\n",
        "    print(s)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[1 2 3 1 2 3]]\n[[4 5 6 4 5 6]]\n[[7 8 9 7 8 9]]\n"
        }
      ],
      "execution_count": 92,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, np.nan, 7, 4, 0])\n",
        "print(arr)\n",
        "sum(arr)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[ 1.  2. nan  7.  4.  0.]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 94,
          "data": {
            "text/plain": "nan"
          },
          "metadata": {}
        }
      ],
      "execution_count": 94,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for x in arr:\n",
        "    if np.isnan(x):\n",
        "        x = 0\n",
        "\n",
        "print(arr)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[0. 0. 0. 0. 0. 0.]\n"
        }
      ],
      "execution_count": 109,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for pos in range(len(arr)):\n",
        "    if not np.isnan(arr[pos]):\n",
        "        arr[pos] = 0\n",
        "        \n",
        "\n",
        "print(arr)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[0. 0. 0. 0. 0. 0.]\n"
        }
      ],
      "execution_count": 110,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "lista = [x for x in arr if not np.isnan(x)]\n",
        "np.array(lista)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 111,
          "data": {
            "text/plain": "array([0., 0., 0., 0., 0., 0.])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 111,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "np.isnan(arr)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 112,
          "data": {
            "text/plain": "array([False, False, False, False, False, False])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 112,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "copia = arr.copy()\n",
        "vista = arr.view()\n",
        "\n",
        "print('original:', arr)\n",
        "print('copia:', copia)\n",
        "print('vista:', vista)\n",
        "\n",
        "arr[0] = 67\n",
        "\n",
        "print('original:', arr)\n",
        "print('copia:', copia)\n",
        "print('vista:', vista)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "original: [0. 0. 0. 0. 0. 0.]\ncopia: [0. 0. 0. 0. 0. 0.]\nvista: [0. 0. 0. 0. 0. 0.]\noriginal: [67.  0.  0.  0.  0.  0.]\ncopia: [0. 0. 0. 0. 0. 0.]\nvista: [67.  0.  0.  0.  0.  0.]\n"
        }
      ],
      "execution_count": 115,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "arr.dtype"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 116,
          "data": {
            "text/plain": "dtype('float64')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 116,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "vista = arr.view(dtype = 'float32')\n",
        "print('vista:', vista)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "vista: [0.        3.2617188 0.        0.        0.        0.        0.\n 0.        0.        0.        0.        0.       ]\n"
        }
      ],
      "execution_count": 117,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "vista = arr.view(dtype = np.int32)\n",
        "print('vista:', vista)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "vista: [         0 1079033856          0          0          0          0\n          0          0          0          0          0          0]\n"
        }
      ],
      "execution_count": 118,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n",
        "arr2 = arr.reshape([2,3,2])\n",
        "print(arr2)\n",
        "arro = arr2.reshape(12)\n",
        "arro"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[[ 1  2]\n  [ 3  4]\n  [ 5  6]]\n\n [[ 7  8]\n  [ 9 10]\n  [11 12]]]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2,3], [4,5,6]])\n",
        "b = np.array([[1,1,1], [2,2,2]])\n",
        "print(a*b)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[ 1  2  3]\n [ 8 10 12]]\n"
        }
      ],
      "execution_count": 36,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2], [4,5]])\n",
        "b = np.array([[1,1], [2,2]])\n",
        "print(a)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[1 2]\n [4 5]]\n"
        }
      ],
      "execution_count": 38,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.linalg.norm(a))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "6.782329983125268\n"
        }
      ],
      "execution_count": 40,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "a.T\n",
        "np.linalg.det(a)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": "-2.9999999999999996"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 1x + 2y = 1\n",
        "# 3x + 5y = 2\n",
        "\n",
        "\n",
        "a = np.array([[1,2], [4,5]])\n",
        "b = np.array([1,2])\n",
        "\n",
        "np.linalg.solve(a,b)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "array([-0.33333333,  0.66666667])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 1"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Crear un array de 1 dimensión con longitud 6\n",
        "array_1d = np.arange(6)\n",
        "\n",
        "# Crear un array de 2 dimensiones con dimensiones 3 x 2\n",
        "array_2d = np.arange(6).reshape(3, 2)\n",
        "\n",
        "# Crear un array de 3 dimensiones con dimensiones 2 x 3 x 4\n",
        "array_3d = np.arange(24).reshape(2, 3, 4)\n",
        "\n",
        "array_1d, array_2d, array_3d\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "(array([0, 1, 2, 3, 4, 5]),\n array([[0, 1],\n        [2, 3],\n        [4, 5]]),\n array([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n \n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 70,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 2"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def resumen_estadistico(array):\n",
        "    \"\"\"\n",
        "    Genera un resumen estadístico básico para un array de 1 dimensión.\n",
        "    Si el array tiene más de una dimensión, muestra un mensaje de alerta.\n",
        "    \"\"\"\n",
        "    if array.ndim > 1:\n",
        "        return \"El array tiene más de una dimensión. Solo se admiten arrays de 1 dimensión.\"\n",
        "    \n",
        "    resumen = {\n",
        "        \"Media\": np.mean(array),\n",
        "        \"Mediana\": np.median(array),\n",
        "        \"Varianza\": np.var(array),\n",
        "        \"Desviación Estándar\": np.std(array),\n",
        "        \"Mínimo\": np.min(array),\n",
        "        \"Máximo\": np.max(array),\n",
        "        \"Primer Cuartil (Q1)\": np.percentile(array, 25),\n",
        "        \"Segundo Cuartil (Mediana)\": np.percentile(array, 50),\n",
        "        \"Tercer Cuartil (Q3)\": np.percentile(array, 75)\n",
        "    }\n",
        "    return resumen\n",
        "\n",
        "# Probar la función con un array de 1 dimensión\n",
        "resumen_1d = resumen_estadistico(array_1d)\n",
        "\n",
        "# Probar la función con un array de más de 1 dimensión\n",
        "mensaje_alerta = resumen_estadistico(array_2d)\n",
        "\n",
        "resumen_1d, mensaje_alerta\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 79,
          "data": {
            "text/plain": "({'Media': 2.5,\n  'Mediana': 2.5,\n  'Varianza': 2.9166666666666665,\n  'Desviación Estándar': 1.707825127659933,\n  'Mínimo': 0,\n  'Máximo': 5,\n  'Primer Cuartil (Q1)': 1.25,\n  'Segundo Cuartil (Mediana)': 2.5,\n  'Tercer Cuartil (Q3)': 3.75},\n 'El array tiene más de una dimensión. Solo se admiten arrays de 1 dimensión.')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 79,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 3 (El array proporcionado tiene 3 dimensiones con una forma de \n",
        "(4,2,3)(4,2,3), lo que significa que:\n",
        "\n",
        "Tiene 4 bloques en la primera dimensión (nivel externo).\n",
        "Cada bloque tiene 2 filas en la segunda dimensión.\n",
        "Cada fila tiene 3 columnas en la tercera dimensión.)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 4"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Crear un array 3x3 con valores aleatorios entre 0 y 100\n",
        "array_random_3x3 = np.random.randint(0, 101, (3, 3))\n",
        "\n",
        "# Función para crear arrays N x N con valores aleatorios entre 0 y 100\n",
        "def crear_array_random(n):\n",
        "    \"\"\"\n",
        "    Crea un array de tamaño N x N con valores aleatorios entre 0 y 100.\n",
        "    \n",
        "    Parámetros:\n",
        "    n (int): Tamaño del array (filas y columnas).\n",
        "    \n",
        "    Retorna:\n",
        "    np.array: Array N x N con valores aleatorios.\n",
        "    \"\"\"\n",
        "    return np.random.randint(0, 101, (n, n))\n",
        "\n",
        "# Probar la función para un array 5x5\n",
        "array_random_5x5 = crear_array_random(5)\n",
        "\n",
        "array_random_3x3, array_random_5x5\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 46,
          "data": {
            "text/plain": "(array([[ 3,  1,  7],\n        [ 6, 75, 80],\n        [85, 66, 44]]),\n array([[88, 93, 44, 84, 44],\n        [71,  7, 46, 10, 36],\n        [79, 82, 77, 96, 17],\n        [40, 92, 49, 93, 21],\n        [10, 15, 35,  3, 52]]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 46,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 5"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_array_marco(numero):\n",
        "    \"\"\"\n",
        "    Crea un array cuadrado de tamaño N x N con un marco de 1's y el resto de 0's.\n",
        "    Si se ejecuta con el número 5, devuelve:\n",
        "    \n",
        "    1 1 1 1 1\n",
        "    1 0 0 0 1\n",
        "    1 0 0 0 1\n",
        "    1 0 0 0 1\n",
        "    1 1 1 1 1\n",
        "    \n",
        "    Parámetros:\n",
        "    numero (int): Tamaño del array.\n",
        "    \n",
        "    Retorna:\n",
        "    np.array: Array con marco de 1's y centro de 0's.\n",
        "    \"\"\"\n",
        "    # Crear un array lleno de 0's\n",
        "    array = np.zeros((numero, numero), dtype=int)\n",
        "    # Rellenar los bordes con 1's\n",
        "    array[0, :] = 1\n",
        "    array[-1, :] = 1\n",
        "    array[:, 0] = 1\n",
        "    array[:, -1] = 1\n",
        "    return array\n",
        "\n",
        "# Probar la función con el número 5\n",
        "array_marco = crear_array_marco(5)\n",
        "array_marco\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "array([[1, 1, 1, 1, 1],\n       [1, 0, 0, 0, 1],\n       [1, 0, 0, 0, 1],\n       [1, 0, 0, 0, 1],\n       [1, 1, 1, 1, 1]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 6"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def detectar_dimensiones_y_faltantes(array):\n",
        "    \"\"\"\n",
        "    Detecta las dimensiones de un array y cuenta la cantidad de datos faltantes (NaN).\n",
        "    \n",
        "    Parámetros:\n",
        "    array (np.array): El array a analizar.\n",
        "    \n",
        "    Retorna:\n",
        "    dict: Diccionario con las dimensiones del array y el número de datos faltantes.\n",
        "    \"\"\"\n",
        "    dimensiones = array.ndim\n",
        "    faltantes = np.isnan(array).sum()\n",
        "    return {\n",
        "        \"Dimensiones\": dimensiones,\n",
        "        \"Datos faltantes (NaN)\": faltantes\n",
        "    }\n",
        "\n",
        "# Crear datos de ejemplo\n",
        "datos_ejemplo = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9]])\n",
        "\n",
        "# Probar la función con los datos de ejemplo\n",
        "resultado = detectar_dimensiones_y_faltantes(datos_ejemplo)\n",
        "datos_ejemplo, resultado\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "(array([[ 1.,  2., nan],\n        [ 4., nan,  6.],\n        [ 7.,  8.,  9.]]),\n {'Dimensiones': 2, 'Datos faltantes (NaN)': 2})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 7"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calcular_margenes(tabla):\n",
        "    \"\"\"\n",
        "    Calcula los márgenes de una tabla: suma por filas, columnas y el total.\n",
        "    Añade estas sumas como una fila y columna extra a la tabla original.\n",
        "    \n",
        "    Parámetros:\n",
        "    tabla (pd.DataFrame): Tabla en forma de DataFrame de Pandas.\n",
        "    \n",
        "    Retorna:\n",
        "    pd.DataFrame: Tabla original con los márgenes calculados añadidos.\n",
        "    \"\"\"\n",
        "    # Calcular la suma por columnas y añadirla como una nueva fila\n",
        "    tabla_con_filas = tabla.copy()\n",
        "    tabla_con_filas.loc['Suma Filas'] = tabla_con_filas.sum(axis=0)\n",
        "    \n",
        "    # Calcular la suma por filas y añadirla como una nueva columna\n",
        "    tabla_con_filas['Suma Columnas'] = tabla_con_filas.sum(axis=1)\n",
        "    \n",
        "    return tabla_con_filas\n",
        "\n",
        "# Crear datos de ejemplo\n",
        "tabla_ejemplo = pd.DataFrame({\n",
        "    'A': [1, 2, 3],\n",
        "    'B': [4, 5, 6],\n",
        "    'C': [7, 8, 9]\n",
        "})\n",
        "\n",
        "# Probar la función con la tabla de ejemplo\n",
        "tabla_con_margenes = calcular_margenes(tabla_ejemplo)\n",
        "\n",
        "print(tabla_con_margenes)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "            A   B   C  Suma Columnas\n0           1   4   7             12\n1           2   5   8             15\n2           3   6   9             18\nSuma Filas  6  15  24             45\n"
        }
      ],
      "execution_count": 51,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio 8"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calcular_coeficiente_correlacion(x, y):\n",
        "    \"\"\"\n",
        "    Calcula el coeficiente de correlación de Pearson entre dos arrays X e Y.\n",
        "    \n",
        "    Parámetros:\n",
        "    x (np.array): Primer array de datos.\n",
        "    y (np.array): Segundo array de datos.\n",
        "    \n",
        "    Retorna:\n",
        "    float: Coeficiente de correlación de Pearson entre X e Y.\n",
        "    \"\"\"\n",
        "    if len(x) != len(y):\n",
        "        raise ValueError(\"Los arrays deben tener la misma longitud.\")\n",
        "    \n",
        "    return np.corrcoef(x, y)[0, 1]\n",
        "\n",
        "# Datos de ejemplo\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "# Calcular el coeficiente de correlación\n",
        "coeficiente_correlacion = calcular_coeficiente_correlacion(x, y)\n",
        "coeficiente_correlacion\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 80,
          "data": {
            "text/plain": "0.9999999999999999"
          },
          "metadata": {}
        }
      ],
      "execution_count": 80,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series([1,2,3,4,5,6])\n",
        "s"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 84,
          "data": {
            "text/plain": "0    1\n1    2\n2    3\n3    4\n4    5\n5    6\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 84,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series({'math':10, 'len':7, 'art':2})\n",
        "s"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 88,
          "data": {
            "text/plain": "math    10\nlen      7\nart      2\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 88,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(s.size)\n",
        "print(s.index)\n",
        "print(s.dtype)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "6\nRangeIndex(start=0, stop=6, step=1)\nint64\n"
        }
      ],
      "execution_count": 85,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(s['math'])\n",
        "print(s[1])\n",
        "print(s[:2])\n",
        "print(s[['len','art']])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "10\n7\nmath    10\nlen      7\ndtype: int64\nlen    7\nart    2\ndtype: int64\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_3790/355217546.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(s[1])\n"
        }
      ],
      "execution_count": 92,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series([1,2,3,4,5,6])\n",
        "print(s.count())\n",
        "print(s.value_counts())\n",
        "print(s.value_counts(normalize=True))\n",
        "print(s.describe())\n",
        "print(s.sum())\n",
        "print(s.cumsum())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "6\n1    1\n2    1\n3    1\n4    1\n5    1\n6    1\nName: count, dtype: int64\n1    0.166667\n2    0.166667\n3    0.166667\n4    0.166667\n5    0.166667\n6    0.166667\nName: proportion, dtype: float64\ncount    6.000000\nmean     3.500000\nstd      1.870829\nmin      1.000000\n25%      2.250000\n50%      3.500000\n75%      4.750000\nmax      6.000000\ndtype: float64\n21\n0     1\n1     3\n2     6\n3    10\n4    15\n5    21\ndtype: int64\n"
        }
      ],
      "execution_count": 98,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "st = pd.Series(['a','b','c'])\n",
        "st*4"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 99,
          "data": {
            "text/plain": "0    aaaa\n1    bbbb\n2    cccc\ndtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 99,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "help(s.apply)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Help on method apply in module pandas.core.series:\n\napply(func: 'AggFuncType', convert_dtype: 'bool | lib.NoDefault' = <no_default>, args: 'tuple[Any, ...]' = (), *, by_row: \"Literal[False, 'compat']\" = 'compat', **kwargs) -> 'DataFrame | Series' method of pandas.core.series.Series instance\n    Invoke function on values of Series.\n    \n    Can be ufunc (a NumPy function that applies to the entire Series)\n    or a Python function that only works on single values.\n    \n    Parameters\n    ----------\n    func : function\n        Python function or NumPy ufunc to apply.\n    convert_dtype : bool, default True\n        Try to find better dtype for elementwise function results. If\n        False, leave as dtype=object. Note that the dtype is always\n        preserved for some extension array dtypes, such as Categorical.\n    \n        .. deprecated:: 2.1.0\n            ``convert_dtype`` has been deprecated. Do ``ser.astype(object).apply()``\n            instead if you want ``convert_dtype=False``.\n    args : tuple\n        Positional arguments passed to func after the series value.\n    by_row : False or \"compat\", default \"compat\"\n        If ``\"compat\"`` and func is a callable, func will be passed each element of\n        the Series, like ``Series.map``. If func is a list or dict of\n        callables, will first try to translate each func into pandas methods. If\n        that doesn't work, will try call to apply again with ``by_row=\"compat\"``\n        and if that fails, will call apply again with ``by_row=False``\n        (backward compatible).\n        If False, the func will be passed the whole Series at once.\n    \n        ``by_row`` has no effect when ``func`` is a string.\n    \n        .. versionadded:: 2.1.0\n    **kwargs\n        Additional keyword arguments passed to func.\n    \n    Returns\n    -------\n    Series or DataFrame\n        If func returns a Series object the result will be a DataFrame.\n    \n    See Also\n    --------\n    Series.map: For element-wise operations.\n    Series.agg: Only perform aggregating type operations.\n    Series.transform: Only perform transforming type operations.\n    \n    Notes\n    -----\n    Functions that mutate the passed object can produce unexpected\n    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n    for more details.\n    \n    Examples\n    --------\n    Create a series with typical summer temperatures for each city.\n    \n    >>> s = pd.Series([20, 21, 12],\n    ...               index=['London', 'New York', 'Helsinki'])\n    >>> s\n    London      20\n    New York    21\n    Helsinki    12\n    dtype: int64\n    \n    Square the values by defining a function and passing it as an\n    argument to ``apply()``.\n    \n    >>> def square(x):\n    ...     return x ** 2\n    >>> s.apply(square)\n    London      400\n    New York    441\n    Helsinki    144\n    dtype: int64\n    \n    Square the values by passing an anonymous function as an\n    argument to ``apply()``.\n    \n    >>> s.apply(lambda x: x ** 2)\n    London      400\n    New York    441\n    Helsinki    144\n    dtype: int64\n    \n    Define a custom function that needs additional positional\n    arguments and pass these additional arguments using the\n    ``args`` keyword.\n    \n    >>> def subtract_custom_value(x, custom_value):\n    ...     return x - custom_value\n    \n    >>> s.apply(subtract_custom_value, args=(5,))\n    London      15\n    New York    16\n    Helsinki     7\n    dtype: int64\n    \n    Define a custom function that takes keyword arguments\n    and pass these arguments to ``apply``.\n    \n    >>> def add_custom_values(x, **kwargs):\n    ...     for month in kwargs:\n    ...         x += kwargs[month]\n    ...     return x\n    \n    >>> s.apply(add_custom_values, june=30, july=20, august=25)\n    London      95\n    New York    96\n    Helsinki    87\n    dtype: int64\n    \n    Use a function from the Numpy library.\n    \n    >>> s.apply(np.log)\n    London      2.995732\n    New York    3.044522\n    Helsinki    2.484907\n    dtype: float64\n\n"
        }
      ],
      "execution_count": 100,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "s.apply(math.log)\n",
        "s.apply(np.sqrt)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 103,
          "data": {
            "text/plain": "0    1.000000\n1    1.414214\n2    1.732051\n3    2.000000\n4    2.236068\n5    2.449490\ndtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 103,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "s.apply(lambda x: x*2+3)\n",
        "sx = pd.Series(['a', 'b', 'c', np.nan, 'd'])\n",
        "print(sx)\n",
        "\n",
        "sy = sx.dropna()\n",
        "print(sy)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0      a\n1      b\n2      c\n3    NaN\n4      d\ndtype: object\n0    a\n1    b\n2    c\n4    d\ndtype: object\n"
        }
      ],
      "execution_count": 106,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "s = pd.Series([1,2,3,4,5,6])\n",
        "\n",
        "mask = s > 2\n",
        "print(mask)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0    False\n1    False\n2     True\n3     True\n4     True\n5     True\ndtype: bool\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1737449752662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sx = pd.Series(['a', 'a', None, 'c', np.nan, 'd'])\n",
        "print(sx)\n",
        "\n",
        "sy = sx.dropna()\n",
        "print(sy)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0       a\n1       a\n2    None\n3       c\n4     NaN\n5       d\ndtype: object\n0    a\n1    a\n3    c\n5    d\ndtype: object\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1737449896793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Serie de datos originales\n",
        "serie = pd.Series([100, 200, 'python', 300.12, 400])\n",
        "print(\"Serie de datos originales:\")\n",
        "print(serie)\n",
        "print(\"Tipo original:\", serie.dtype)\n",
        "\n",
        "# Convertir la serie a tipo numérico (convirtiendo valores no numéricos en NaN)\n",
        "serie_numerica = pd.to_numeric(serie, errors='coerce')\n",
        "\n",
        "# Mostrar la serie convertida\n",
        "print(\"\\nCambio a numérico:\")\n",
        "print(serie_numerica)\n",
        "print(\"Tipo:\", serie_numerica.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie de datos originales:\n0       100\n1       200\n2    python\n3    300.12\n4       400\ndtype: object\nTipo original: object\n\nCambio a numérico:\n0    100.00\n1    200.00\n2       NaN\n3    300.12\n4    400.00\ndtype: float64\nTipo: float64\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1737450406689
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Serie de listas de colores\n",
        "serie_listas = pd.Series([['Red', 'Green', 'White'], ['Red', 'Black'], ['Yellow']])\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie original de listas:\")\n",
        "print(serie_listas)\n",
        "\n",
        "# Convertir la serie de listas en una serie plana\n",
        "serie_plana = serie_listas.explode()\n",
        "\n",
        "# Mostrar la serie transformada\n",
        "print(\"\\nUna serie:\")\n",
        "print(serie_plana)\n",
        "print(\"dtype:\", serie_plana.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie original de listas:\n0    [Red, Green, White]\n1           [Red, Black]\n2               [Yellow]\ndtype: object\n\nUna serie:\n0       Red\n0     Green\n0     White\n1       Red\n1     Black\n2    Yellow\ndtype: object\ndtype: object\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1737450574194
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Serie de datos original\n",
        "serie = pd.Series([100, 200, 'python', 300.12, 400])\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie de datos originales:\")\n",
        "print(serie)\n",
        "print(\"dtype:\", serie.dtype)\n",
        "\n",
        "# Datos a agregar\n",
        "nuevos_datos = pd.Series([500, 'php'])\n",
        "\n",
        "# Concatenar la serie original con los nuevos datos\n",
        "serie_actualizada = pd.concat([serie, nuevos_datos], ignore_index=True)\n",
        "\n",
        "# Mostrar la serie después de agregar datos\n",
        "print(\"\\nSerie de datos después de agregar algunos datos:\")\n",
        "print(serie_actualizada)\n",
        "print(\"dtype:\", serie_actualizada.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie de datos originales:\n0       100\n1       200\n2    python\n3    300.12\n4       400\ndtype: object\ndtype: object\n\nSerie de datos después de agregar algunos datos:\n0       100\n1       200\n2    python\n3    300.12\n4       400\n5       500\n6       php\ndtype: object\ndtype: object\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1737450889448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear la serie de datos original\n",
        "serie = pd.Series(range(11))  # Crea valores de 0 a 10\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie de datos originales:\")\n",
        "print(serie)\n",
        "print(\"tipo:\", serie.dtype)\n",
        "\n",
        "# Aplicar una condición para obtener un subconjunto (valores menores o iguales a 5)\n",
        "subserie = serie[serie <= 5]\n",
        "\n",
        "# Mostrar la subserie resultante\n",
        "print(\"\\nSubconjunto de la serie de datos anterior:\")\n",
        "print(subserie)\n",
        "print(\"tipo:\", subserie.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie de datos originales:\n0      0\n1      1\n2      2\n3      3\n4      4\n5      5\n6      6\n7      7\n8      8\n9      9\n10    10\ndtype: int64\ntipo: int64\n\nSubconjunto de la serie de datos anterior:\n0    0\n1    1\n2    2\n3    3\n4    4\n5    5\ndtype: int64\ntipo: int64\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1737451092076
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear la serie de datos original con índice personalizado\n",
        "serie = pd.Series([1, 2, 3, 4, 5], index=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie de datos originales:\")\n",
        "print(serie)\n",
        "print(\"tipo:\", serie.dtype)\n",
        "\n",
        "# Cambiar el orden del índice de la serie\n",
        "nuevo_orden = ['B', 'A', 'C', 'D', 'E']\n",
        "serie_reordenada = serie.reindex(nuevo_orden)\n",
        "\n",
        "# Mostrar la serie después de cambiar el orden del índice\n",
        "print(\"\\nSerie de datos después de cambiar el orden del índice:\")\n",
        "print(serie_reordenada)\n",
        "print(\"tipo:\", serie_reordenada.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie de datos originales:\nA    1\nB    2\nC    3\nD    4\nE    5\ndtype: int64\ntipo: int64\n\nSerie de datos después de cambiar el orden del índice:\nB    2\nA    1\nC    3\nD    4\nE    5\ndtype: int64\ntipo: int64\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1737451438708
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear las series de datos originales\n",
        "sr1 = pd.Series([1, 2, 3, 4, 5])\n",
        "sr2 = pd.Series([2, 4, 6, 8, 10])\n",
        "\n",
        "# Mostrar las series originales\n",
        "print(\"Serie original:\")\n",
        "print(\"sr1:\")\n",
        "print(sr1)\n",
        "print(\"sr2:\")\n",
        "print(sr2)\n",
        "\n",
        "# Obtener los elementos de sr1 que no están en sr2\n",
        "sr1_unicos = sr1[~sr1.isin(sr2)]\n",
        "\n",
        "# Mostrar los elementos únicos de sr1\n",
        "print(\"\\nElementos de sr1 no presentes en sr2:\")\n",
        "print(sr1_unicos)\n",
        "print(\"tipo:\", sr1_unicos.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie original:\nsr1:\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64\nsr2:\n0     2\n1     4\n2     6\n3     8\n4    10\ndtype: int64\n\nElementos de sr1 no presentes en sr2:\n0    1\n2    3\n4    5\ndtype: int64\ntipo: int64\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1737451797740
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Crear una serie de ejemplo con valores repetidos\n",
        "serie = pd.Series(np.random.randint(0, 10, size=40))  # Genera 40 números entre 0 y 9\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie original:\")\n",
        "print(serie)\n",
        "\n",
        "# Calcular la frecuencia de cada valor único\n",
        "frecuencia = serie.value_counts()\n",
        "\n",
        "# Mostrar los conteos de frecuencia\n",
        "print(\"\\nFrecuencia de cada valor único de dicha serie:\")\n",
        "print(frecuencia)\n",
        "print(\"tipo:\", frecuencia.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie original:\n0     0\n1     3\n2     2\n3     1\n4     8\n5     3\n6     3\n7     5\n8     1\n9     8\n10    1\n11    9\n12    6\n13    3\n14    0\n15    4\n16    2\n17    1\n18    2\n19    1\n20    5\n21    8\n22    9\n23    6\n24    5\n25    1\n26    6\n27    0\n28    3\n29    3\n30    8\n31    7\n32    3\n33    0\n34    4\n35    2\n36    3\n37    1\n38    7\n39    6\ndtype: int64\n\nFrecuencia de cada valor único de dicha serie:\n3    8\n1    7\n0    4\n2    4\n8    4\n6    4\n5    3\n9    2\n4    2\n7    2\nName: count, dtype: int64\ntipo: int64\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1737451977959
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear una serie de ejemplo\n",
        "serie = pd.Series([3, 1, 1, 3, 2, 3, 1, 2, 2, 3, 1, 3, 2, 3, 3])\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie original:\")\n",
        "print(serie)\n",
        "\n",
        "# Obtener las frecuencias de cada valor\n",
        "frecuencias = serie.value_counts()\n",
        "\n",
        "# Mostrar las frecuencias\n",
        "print(\"\\nFrecuencias principales:\")\n",
        "print(frecuencias)\n",
        "print(\"tipo:\", frecuencias.dtype)\n",
        "\n",
        "# Obtener el valor más frecuente\n",
        "valor_mas_frecuente = frecuencias.idxmax()\n",
        "\n",
        "# Reemplazar todos los valores excepto el más frecuente con 'Otro'\n",
        "serie_reemplazada = serie.apply(lambda x: x if x == valor_mas_frecuente else 'Otro')\n",
        "\n",
        "# Mostrar la serie después de reemplazar\n",
        "print(\"\\nSerie después de reemplazar valores no frecuentes con 'Otro':\")\n",
        "print(serie_reemplazada)\n",
        "print(\"dtype:\", serie_reemplazada.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie original:\n0     3\n1     1\n2     1\n3     3\n4     2\n5     3\n6     1\n7     2\n8     2\n9     3\n10    1\n11    3\n12    2\n13    3\n14    3\ndtype: int64\n\nFrecuencias principales:\n3    7\n1    4\n2    4\nName: count, dtype: int64\ntipo: int64\n\nSerie después de reemplazar valores no frecuentes con 'Otro':\n0        3\n1     Otro\n2     Otro\n3        3\n4     Otro\n5        3\n6     Otro\n7     Otro\n8     Otro\n9        3\n10    Otro\n11       3\n12    Otro\n13       3\n14       3\ndtype: object\ndtype: object\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1737452203672
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir la serie original\n",
        "serie1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Definir la serie con elementos a buscar\n",
        "serie2 = pd.Series([1, 3, 5, 7, 10])\n",
        "\n",
        "# Mostrar las series originales\n",
        "print(\"Serie original:\")\n",
        "print(serie1)\n",
        "print(\"tipo:\", serie1.dtype)\n",
        "\n",
        "print(\"\\nElementos a buscar en la serie original:\")\n",
        "print(serie2)\n",
        "print(\"tipo:\", serie2.dtype)\n",
        "\n",
        "# Obtener las posiciones de los elementos de serie2 en serie1\n",
        "posiciones = serie1[serie1.isin(serie2)].index.tolist()\n",
        "\n",
        "# Mostrar las posiciones encontradas\n",
        "print(\"\\nPosiciones de los elementos de la serie 2 en la serie 1:\")\n",
        "print(posiciones)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie original:\n0     1\n1     2\n2     3\n3     4\n4     5\n5     6\n6     7\n7     8\n8     9\n9    10\ndtype: int64\ntipo: int64\n\nElementos a buscar en la serie original:\n0     1\n1     3\n2     5\n3     7\n4    10\ndtype: int64\ntipo: int64\n\nPosiciones de los elementos de la serie 2 en la serie 1:\n[0, 2, 4, 6, 9]\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1737452484054
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear la serie de ejemplo\n",
        "serie = pd.Series(['php', 'python', 'java', 'c#'])\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie original:\")\n",
        "print(serie)\n",
        "\n",
        "# Función para convertir el primer y último carácter en mayúscula\n",
        "def capitalizar_extremos(palabra):\n",
        "    if len(palabra) > 1:\n",
        "        return palabra[0].upper() + palabra[1:-1] + palabra[-1].upper()\n",
        "    else:\n",
        "        return palabra.upper()\n",
        "\n",
        "# Aplicar la función a cada elemento de la serie\n",
        "serie_modificada = serie.apply(capitalizar_extremos)\n",
        "\n",
        "# Mostrar la serie transformada\n",
        "print(\"\\nPrimer y último carácter de cada palabra en mayúscula:\")\n",
        "print(serie_modificada)\n",
        "print(\"dtype:\", serie_modificada.dtype)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie original:\n0       php\n1    python\n2      java\n3        c#\ndtype: object\n\nPrimer y último carácter de cada palabra en mayúscula:\n0       PhP\n1    PythoN\n2      JavA\n3        C#\ndtype: object\ndtype: object\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1737452678355
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear la serie de ejemplo\n",
        "serie = pd.Series([1, 3, 5, 8, 10, 11, 15])\n",
        "\n",
        "# Mostrar la serie original\n",
        "print(\"Serie original:\")\n",
        "print(serie)\n",
        "print(\"tipo:\", serie.dtype)\n",
        "\n",
        "# Calcular la primera diferencia (diferencias consecutivas)\n",
        "primera_diferencia = serie.diff()\n",
        "\n",
        "# Calcular la segunda diferencia (diferencia de diferencias)\n",
        "segunda_diferencia = primera_diferencia.diff()\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"\\nDiferencia entre números consecutivos de la serie:\")\n",
        "print(primera_diferencia.tolist())\n",
        "\n",
        "print(\"\\nDiferencia de diferencias entre números consecutivos de la serie:\")\n",
        "print(segunda_diferencia.tolist())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Serie original:\n0     1\n1     3\n2     5\n3     8\n4    10\n5    11\n6    15\ndtype: int64\ntipo: int64\n\nDiferencia entre números consecutivos de la serie:\n[nan, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0]\n\nDiferencia de diferencias entre números consecutivos de la serie:\n[nan, nan, 0.0, 1.0, -1.0, -1.0, 3.0]\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1737452899789
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Configuración de conexión (ajusta según tu base de datos)\n",
        "db_tipo = 'postgresql'  # Ejemplo: 'mysql', 'sqlite', 'mssql'\n",
        "usuario = 'tu_usuario'\n",
        "contraseña = 'tu_contraseña'\n",
        "host = 'localhost'  # o la dirección IP del servidor\n",
        "puerto = '5432'  # Puerto por defecto de PostgreSQL\n",
        "db_nombre = 'datafundamentals'\n",
        "\n",
        "# Crear la cadena de conexión\n",
        "conexion_str = f'{db_tipo}://{usuario}:{contraseña}@{host}:{puerto}/{db_nombre}'\n",
        "\n",
        "# Crear el motor de conexión\n",
        "engine = create_engine(conexion_str)\n",
        "\n",
        "# Cargar la tabla 'pagos' en un DataFrame de Pandas\n",
        "try:\n",
        "    df_pagos = pd.read_sql('SELECT * FROM pagos', engine)\n",
        "    print(\"Datos cargados correctamente:\")\n",
        "    print(df_pagos.head())  # Mostrar los primeros registros\n",
        "except Exception as e:\n",
        "    print(\"Error al cargar los datos:\", e)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Configuración de conexión a la base de datos\n",
        "db_tipo = 'postgresql'  # Cambiar a 'mysql+mysqlconnector' para MySQL\n",
        "usuario = 'tu_usuario'\n",
        "contraseña = 'tu_contraseña'\n",
        "host = 'localhost'  # Cambia por la dirección IP del servidor si es necesario\n",
        "puerto = '5432'  # Puerto por defecto de PostgreSQL\n",
        "db_nombre = 'datafundamentals'\n",
        "\n",
        "# Crear la cadena de conexión\n",
        "db_url = f'{db_tipo}://{usuario}:{contraseña}@{host}:{puerto}/{db_nombre}'\n",
        "\n",
        "# Crear motor de conexión\n",
        "engine = create_engine(db_url)\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "df_pagos = pd.DataFrame({\n",
        "    'id_pago': [1, 2, 3],\n",
        "    'monto': [100.50, 200.75, 150.00],\n",
        "    'fecha': ['2023-01-01', '2023-02-01', '2023-03-01']\n",
        "})\n",
        "\n",
        "# Guardar el DataFrame en la base de datos como una nueva tabla llamada 'pagos_nueva'\n",
        "df_pagos.to_sql('pagos_nueva', engine, if_exists='replace', index=False)\n",
        "\n",
        "print(\"Datos guardados en la tabla 'pagos_nueva' correctamente.\")\n",
        "\n",
        "# Consultar las tablas existentes en la base de datos\n",
        "query_list_tables = \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"\n",
        "\n",
        "# Leer la lista de tablas en un DataFrame de Pandas\n",
        "df_tablas = pd.read_sql(query_list_tables, engine)\n",
        "\n",
        "# Mostrar las tablas de la base de datos\n",
        "print(\"\\nTablas existentes en la base de datos:\")\n",
        "print(df_tablas)\n",
        "\n",
        "# Comprobar si la nueva tabla existe\n",
        "if 'pagos_nueva' in df_tablas['table_name'].values:\n",
        "    print(\"\\n¡La tabla 'pagos_nueva' existe en la base de datos!\")\n",
        "else:\n",
        "    print(\"\\nLa tabla 'pagos_nueva' NO fue encontrada en la base de datos.\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "data = {\n",
        "    'id': [1, 2, 3, 4, 5],\n",
        "    'name': ['Ana', 'Luis', 'Carlos', 'Beatriz', 'Pedro'],\n",
        "    'amount': [300, 450, 500, 200, 600]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar el DataFrame original\n",
        "print(\"DataFrame original:\")\n",
        "print(df)\n",
        "\n",
        "# Filtrar filas donde 'amount' sea mayor que 400\n",
        "df_filtrado = df[df['amount'] > 400]\n",
        "\n",
        "# Mostrar el DataFrame filtrado\n",
        "print(\"\\nFilas donde 'amount' es mayor que 400:\")\n",
        "print(df_filtrado)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DataFrame original:\n   id     name  amount\n0   1      Ana     300\n1   2     Luis     450\n2   3   Carlos     500\n3   4  Beatriz     200\n4   5    Pedro     600\n\nFilas donde 'amount' es mayor que 400:\n   id    name  amount\n1   2    Luis     450\n2   3  Carlos     500\n4   5   Pedro     600\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1737454609736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo con varias columnas\n",
        "data = {\n",
        "    'checknumber': ['CHK001', 'CHK002', 'CHK003', 'CHK004'],\n",
        "    'paymentdate': ['2023-01-10', '2023-02-15', '2023-03-20', '2023-04-25'],\n",
        "    'amount': [500, 300, 450, 600],\n",
        "    'customer': ['Ana', 'Luis', 'Carlos', 'Beatriz']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar el DataFrame original\n",
        "print(\"DataFrame original:\")\n",
        "print(df)\n",
        "\n",
        "# Seleccionar solo las columnas \"checknumber\" y \"paymentdate\"\n",
        "df_seleccionado = df[['checknumber', 'paymentdate']]\n",
        "\n",
        "# Mostrar el DataFrame con las columnas seleccionadas\n",
        "print(\"\\nDataFrame con columnas seleccionadas:\")\n",
        "print(df_seleccionado)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DataFrame original:\n  checknumber paymentdate  amount customer\n0      CHK001  2023-01-10     500      Ana\n1      CHK002  2023-02-15     300     Luis\n2      CHK003  2023-03-20     450   Carlos\n3      CHK004  2023-04-25     600  Beatriz\n\nDataFrame con columnas seleccionadas:\n  checknumber paymentdate\n0      CHK001  2023-01-10\n1      CHK002  2023-02-15\n2      CHK003  2023-03-20\n3      CHK004  2023-04-25\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1737454673876
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "data = {\n",
        "    'Region': ['Norte', 'Norte', 'Sur', 'Sur', 'Este', 'Este'],\n",
        "    'Ciudad': ['Madrid', 'Barcelona', 'Sevilla', 'Granada', 'Valencia', 'Alicante'],\n",
        "    'Ventas': [1000, 1200, 800, 750, 950, 1100]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Definir un MultiIndex basado en las columnas 'Region' y 'Ciudad'\n",
        "df.set_index(['Region', 'Ciudad'], inplace=True)\n",
        "\n",
        "# Mostrar el DataFrame con el MultiIndex\n",
        "print(\"DataFrame con MultiIndex:\")\n",
        "print(df)\n",
        "\n",
        "# Acceder a datos específicos con MultiIndex\n",
        "print(\"\\nAcceder a datos de la ciudad 'Madrid' en la región 'Norte':\")\n",
        "print(df.loc[('Norte', 'Madrid')])\n",
        "\n",
        "# Segmentar el DataFrame por nivel de índice (seleccionar todas las ciudades de una región)\n",
        "print(\"\\nDatos de la región 'Sur':\")\n",
        "print(df.loc['Sur'])\n",
        "\n",
        "# Acceder a todas las ciudades de la región 'Norte' con el método xs\n",
        "print(\"\\nDatos de la región 'Norte' usando xs:\")\n",
        "print(df.xs('Norte', level='Region'))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "data = {\n",
        "    'ID': [1, 2, 3, 4, 5],\n",
        "    'Nombre': ['Ana', 'Luis', 'Carlos', 'Beatriz', 'Pedro'],\n",
        "    'Edad': [25, 30, 22, 28, 35]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar el DataFrame original\n",
        "print(\"DataFrame original:\")\n",
        "print(df)\n",
        "\n",
        "# Seleccionar las primeras tres filas usando iloc\n",
        "df_tres_filas = df.iloc[:3]\n",
        "\n",
        "# Mostrar las primeras tres filas seleccionadas\n",
        "print(\"\\nPrimeras tres filas del DataFrame:\")\n",
        "print(df_tres_filas)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DataFrame original:\n   ID   Nombre  Edad\n0   1      Ana    25\n1   2     Luis    30\n2   3   Carlos    22\n3   4  Beatriz    28\n4   5    Pedro    35\n\nPrimeras tres filas del DataFrame:\n   ID  Nombre  Edad\n0   1     Ana    25\n1   2    Luis    30\n2   3  Carlos    22\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1737455132571
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "data = {\n",
        "    'Nombre': ['Ana', 'Luis', 'Carlos', 'Beatriz', 'Pedro'],\n",
        "    'Edad': [25, 30, 22, 28, 35],\n",
        "    'Salario': [50000, 60000, 40000, 55000, 65000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar el DataFrame original\n",
        "print(\"DataFrame original:\")\n",
        "print(df)\n",
        "\n",
        "# Aplicar condición en dos columnas: seleccionar personas con Edad > 25 y Salario > 50000\n",
        "df_filtrado = df.loc[(df['Edad'] > 25) & (df['Salario'] > 50000)]\n",
        "\n",
        "# Mostrar las filas filtradas\n",
        "print(\"\\nFilas donde la Edad > 25 y el Salario > 50000:\")\n",
        "print(df_filtrado)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DataFrame original:\n    Nombre  Edad  Salario\n0      Ana    25    50000\n1     Luis    30    60000\n2   Carlos    22    40000\n3  Beatriz    28    55000\n4    Pedro    35    65000\n\nFilas donde la Edad > 25 y el Salario > 50000:\n    Nombre  Edad  Salario\n1     Luis    30    60000\n3  Beatriz    28    55000\n4    Pedro    35    65000\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1737455313541
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "data = {\n",
        "    'ID': [1, 2, 3, 4, 5],\n",
        "    'Cliente': ['Ana', 'Luis', 'Carlos', 'Beatriz', 'Pedro'],\n",
        "    'Amount': [300, 450, 500, 200, 600]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar el DataFrame original\n",
        "print(\"DataFrame original:\")\n",
        "print(df)\n",
        "\n",
        "# Condición: Cambiar 'Amount' a 999 donde 'Amount' sea mayor que 400\n",
        "df.loc[df['Amount'] > 400, 'Amount'] = 999\n",
        "\n",
        "# Mostrar el DataFrame después de la modificación\n",
        "print(\"\\nDataFrame después de modificar la columna 'Amount':\")\n",
        "print(df)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DataFrame original:\n   ID  Cliente  Amount\n0   1      Ana     300\n1   2     Luis     450\n2   3   Carlos     500\n3   4  Beatriz     200\n4   5    Pedro     600\n\nDataFrame después de modificar la columna 'Amount':\n   ID  Cliente  Amount\n0   1      Ana     300\n1   2     Luis     999\n2   3   Carlos     999\n3   4  Beatriz     200\n4   5    Pedro     999\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1737455597979
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "data = {\n",
        "    'Producto': ['Manzana', 'Banana', 'Cereza', 'Durazno', 'Fresa'],\n",
        "    'Cantidad': [10, 20, 15, 25, 30],\n",
        "    'Precio': [1.5, 0.8, 2.0, 2.5, 1.8]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data, index=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "# Mostrar el DataFrame original\n",
        "print(\"DataFrame original:\")\n",
        "print(df)\n",
        "\n",
        "# Dividir el DataFrame seleccionando filas 'A' a 'C' y columnas 'Producto' y 'Cantidad'\n",
        "df_subconjunto = df.loc['A':'C', ['Producto', 'Cantidad']]\n",
        "\n",
        "# Mostrar el subconjunto del DataFrame\n",
        "print(\"\\nSubconjunto del DataFrame con filas 'A' a 'C' y columnas 'Producto' y 'Cantidad':\")\n",
        "print(df_subconjunto)\n",
        "\n",
        "# Otra segmentación seleccionando filas específicas y columnas específicas\n",
        "df_segmento = df.loc[['B', 'D'], ['Producto', 'Precio']]\n",
        "\n",
        "# Mostrar otra segmentación\n",
        "print(\"\\nSegmento del DataFrame con filas 'B' y 'D' y columnas 'Producto' y 'Precio':\")\n",
        "print(df_segmento)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DataFrame original:\n  Producto  Cantidad  Precio\nA  Manzana        10     1.5\nB   Banana        20     0.8\nC   Cereza        15     2.0\nD  Durazno        25     2.5\nE    Fresa        30     1.8\n\nSubconjunto del DataFrame con filas 'A' a 'C' y columnas 'Producto' y 'Cantidad':\n  Producto  Cantidad\nA  Manzana        10\nB   Banana        20\nC   Cereza        15\n\nSegmento del DataFrame con filas 'B' y 'D' y columnas 'Producto' y 'Precio':\n  Producto  Precio\nB   Banana     0.8\nD  Durazno     2.5\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1737455729079
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame con MultiIndex\n",
        "arrays = [\n",
        "    ['Norte', 'Norte', 'Sur', 'Sur', 'Este', 'Este'],\n",
        "    ['Madrid', 'Barcelona', 'Sevilla', 'Granada', 'Valencia', 'Alicante']\n",
        "]\n",
        "index = pd.MultiIndex.from_tuples(list(zip(*arrays)), names=['Region', 'Ciudad'])\n",
        "\n",
        "data = {\n",
        "    'Poblacion': [3200000, 1600000, 700000, 500000, 800000, 330000],\n",
        "    'PIB': [30000, 28000, 22000, 21000, 25000, 23000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data, index=index)\n",
        "\n",
        "# Mostrar el DataFrame con MultiIndex\n",
        "print(\"DataFrame con MultiIndex:\")\n",
        "print(df)\n",
        "\n",
        "# 1. Seleccionar datos de una región específica (ej. 'Norte')\n",
        "print(\"\\nSegmentación por región 'Norte':\")\n",
        "df_norte = df.loc['Norte']\n",
        "print(df_norte)\n",
        "\n",
        "# 2. Seleccionar datos de una ciudad específica dentro de una región\n",
        "print(\"\\nSegmentación por 'Norte' y ciudad 'Madrid':\")\n",
        "df_madrid = df.loc[('Norte', 'Madrid')]\n",
        "print(df_madrid)\n",
        "\n",
        "# 3. Seleccionar datos de múltiples ciudades dentro de una región\n",
        "print(\"\\nSegmentación por múltiples ciudades en 'Sur':\")\n",
        "df_sur = df.loc[('Sur', ['Sevilla', 'Granada']), :]\n",
        "print(df_sur)\n",
        "\n",
        "# 4. Seleccionar una columna específica con multi-índice\n",
        "print(\"\\nSegmentación para obtener la columna 'PIB' de la región 'Este':\")\n",
        "df_este_pib = df.loc['Este', 'PIB']\n",
        "print(df_este_pib)\n",
        "\n",
        "# 5. Seleccionar datos con múltiples niveles de índices\n",
        "print(\"\\nSegmentación específica: Región 'Norte' y todas las columnas:\")\n",
        "df_norte_todas_columnas = df.loc[('Norte', slice(None)), :]\n",
        "print(df_norte_todas_columnas)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "DataFrame con MultiIndex:\n                  Poblacion    PIB\nRegion Ciudad                     \nNorte  Madrid       3200000  30000\n       Barcelona    1600000  28000\nSur    Sevilla       700000  22000\n       Granada       500000  21000\nEste   Valencia      800000  25000\n       Alicante      330000  23000\n\nSegmentación por región 'Norte':\n           Poblacion    PIB\nCiudad                     \nMadrid       3200000  30000\nBarcelona    1600000  28000\n\nSegmentación por 'Norte' y ciudad 'Madrid':\nPoblacion    3200000\nPIB            30000\nName: (Norte, Madrid), dtype: int64\n\nSegmentación por múltiples ciudades en 'Sur':\n                Poblacion    PIB\nRegion Ciudad                   \nSur    Sevilla     700000  22000\n       Granada     500000  21000\n\nSegmentación para obtener la columna 'PIB' de la región 'Este':\nCiudad\nValencia    25000\nAlicante    23000\nName: PIB, dtype: int64\n\nSegmentación específica: Región 'Norte' y todas las columnas:\n                  Poblacion    PIB\nRegion Ciudad                     \nNorte  Madrid       3200000  30000\n       Barcelona    1600000  28000\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1737455903540
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Ejercicio 1: Concatenación de DataFrames por Filas\n",
        "df1 = pd.DataFrame({\n",
        "    'Nombre': ['Ana', 'Luis', 'Marta'],\n",
        "    'Grado': ['10°', '10°', '10°'],\n",
        "    'Promedio': [8.5, 7.8, 9.0]\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    'Nombre': ['Carlos', 'Lucía'],\n",
        "    'Grado': ['11°', '11°'],\n",
        "    'Promedio': [8.2, 9.3]\n",
        "})\n",
        "\n",
        "df_combinado_filas = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "print(\"Concatenación por filas (Ejercicio 1):\")\n",
        "print(df_combinado_filas)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Concatenación por filas (Ejercicio 1):\n   Nombre Grado  Promedio\n0     Ana   10°       8.5\n1    Luis   10°       7.8\n2   Marta   10°       9.0\n3  Carlos   11°       8.2\n4   Lucía   11°       9.3\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1738056865690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2: Concatenación de DataFrames por Columnas\n",
        "df_productos = pd.DataFrame({\n",
        "    'ID_Producto': [1, 2, 3],\n",
        "    'Nombre': ['Manzanas', 'Plátanos', 'Naranjas']\n",
        "})\n",
        "\n",
        "df_precios = pd.DataFrame({\n",
        "    'Precio': [1.2, 0.8, 1.5],\n",
        "    'Stock': [100, 200, 150]\n",
        "})\n",
        "\n",
        "df_combinado_columnas = pd.concat([df_productos, df_precios], axis=1)\n",
        "print(\"\\nConcatenación por columnas (Ejercicio 2):\")\n",
        "print(df_combinado_columnas)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nConcatenación por columnas (Ejercicio 2):\n   ID_Producto    Nombre  Precio  Stock\n0            1  Manzanas     1.2    100\n1            2  Plátanos     0.8    200\n2            3  Naranjas     1.5    150\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1738056956205
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 3: Uso de pd.cut para Agrupar Datos\n",
        "df_ventas = pd.DataFrame({\n",
        "    'ID_Venta': [101, 102, 103, 104, 105],\n",
        "    'Monto': [200, 450, 300, 150, 500]\n",
        "})\n",
        "\n",
        "df_ventas['Categoría'] = pd.cut(df_ventas['Monto'], bins=[0, 200, 400, float('inf')], labels=['Bajo', 'Medio', 'Alto'])\n",
        "print(\"\\nAgrupación con pd.cut (Ejercicio 3):\")\n",
        "print(df_ventas)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nAgrupación con pd.cut (Ejercicio 3):\n   ID_Venta  Monto Categoría\n0       101    200      Bajo\n1       102    450      Alto\n2       103    300     Medio\n3       104    150      Bajo\n4       105    500      Alto\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1738057043236
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 4: Concatenación y Operaciones Mixtas\n",
        "ventas_enero = pd.DataFrame({\n",
        "    'ID_Venta': [1, 2, 3],\n",
        "    'Producto': ['A', 'B', 'C'],\n",
        "    'Monto': [500, 300, 450]\n",
        "})\n",
        "\n",
        "ventas_febrero = pd.DataFrame({\n",
        "    'ID_Venta': [4, 5, 6],\n",
        "    'Producto': ['A', 'B', 'D'],\n",
        "    'Monto': [700, 200, 600]\n",
        "})\n",
        "\n",
        "ventas_totales = pd.concat([ventas_enero, ventas_febrero], ignore_index=True)\n",
        "ventas_totales['Categoría'] = pd.cut(ventas_totales['Monto'], bins=[0, 300, 600, float('inf')], labels=['Bajo', 'Medio', 'Alto'])\n",
        "monto_total = ventas_totales['Monto'].sum()\n",
        "print(\"\\nConcatenación y Categorías (Ejercicio 4):\")\n",
        "print(ventas_totales)\n",
        "print(f\"Total de Ventas: {monto_total}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nConcatenación y Categorías (Ejercicio 4):\n   ID_Venta Producto  Monto Categoría\n0         1        A    500     Medio\n1         2        B    300      Bajo\n2         3        C    450     Medio\n3         4        A    700      Alto\n4         5        B    200      Bajo\n5         6        D    600     Medio\nTotal de Ventas: 2750\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1738057118594
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 5: Concatenación con Índices Desajustados\n",
        "df_a = pd.DataFrame({'A': [1, 2]}, index=[0, 1])\n",
        "df_b = pd.DataFrame({'B': [3, 4]}, index=[2, 3])\n",
        "\n",
        "concatenado_desajustado = pd.concat([df_a, df_b], axis=1)\n",
        "concatenado_alineado = pd.concat([df_a, df_b], axis=1, ignore_index=True)\n",
        "print(\"\\nConcatenación con índices desajustados (Ejercicio 5):\")\n",
        "print(concatenado_desajustado)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nConcatenación con índices desajustados (Ejercicio 5):\n     A    B\n0  1.0  NaN\n1  2.0  NaN\n2  NaN  3.0\n3  NaN  4.0\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1738057226346
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 6: Crear un DataFrame y usar pd.cut\n",
        "np.random.seed(42)\n",
        "edades = np.random.randint(18, 65, size=20)\n",
        "df_edades = pd.DataFrame({'Edad': edades})\n",
        "df_edades['Grupo_Edad'] = pd.cut(df_edades['Edad'], bins=[18, 25, 45, 65], labels=['Joven', 'Adulto', 'Mayor'])\n",
        "print(\"\\nEdades categorizadas (Ejercicio 6):\")\n",
        "print(df_edades)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nEdades categorizadas (Ejercicio 6):\n    Edad Grupo_Edad\n0     56      Mayor\n1     46      Mayor\n2     32     Adulto\n3     60      Mayor\n4     25      Joven\n5     38     Adulto\n6     56      Mayor\n7     36     Adulto\n8     40     Adulto\n9     28     Adulto\n10    28     Adulto\n11    41     Adulto\n12    53      Mayor\n13    57      Mayor\n14    41     Adulto\n15    20      Joven\n16    39     Adulto\n17    19      Joven\n18    41     Adulto\n19    61      Mayor\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1738057380523
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 7: Concatenación con Claves\n",
        "ventas_norte = pd.DataFrame({'Producto': ['A', 'B'], 'Monto': [300, 400]})\n",
        "ventas_sur = pd.DataFrame({'Producto': ['C', 'D'], 'Monto': [200, 500]})\n",
        "\n",
        "ventas_por_region = pd.concat([ventas_norte, ventas_sur], keys=['Norte', 'Sur'])\n",
        "print(\"\\nVentas por región (Ejercicio 7):\")\n",
        "print(ventas_por_region)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nVentas por región (Ejercicio 7):\n        Producto  Monto\nNorte 0        A    300\n      1        B    400\nSur   0        C    200\n      1        D    500\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1738057431171
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ventas de enero y febrero\n",
        "ventas_totales = pd.DataFrame({\n",
        "    'ID_Venta': [1, 2, 3, 4, 5, 6],\n",
        "    'Producto': ['A', 'B', 'C', 'A', 'B', 'D'],\n",
        "    'Monto': [500, 300, 450, 700, 200, 600]\n",
        "})\n",
        "\n",
        "# Generación de edades aleatorias\n",
        "np.random.seed(42)\n",
        "edades = np.random.randint(18, 65, size=6)  # Ajustado al número de filas de ventas_totales\n",
        "df_edades = pd.DataFrame({'Edad': edades})\n",
        "\n",
        "# Combinación de datos\n",
        "datos_totales = pd.concat([ventas_totales, df_edades], axis=1)\n",
        "\n",
        "# Agregar categorías para las edades y los montos\n",
        "datos_totales['Grupo_Edad'] = pd.cut(\n",
        "    datos_totales['Edad'],\n",
        "    bins=[18, 25, 45, 65],\n",
        "    labels=['Joven', 'Adulto', 'Mayor']\n",
        ")\n",
        "\n",
        "datos_totales['Rango_Ventas'] = pd.cut(\n",
        "    datos_totales['Monto'],\n",
        "    bins=[0, 300, 600, float('inf')],\n",
        "    labels=['Bajo', 'Medio', 'Alto']\n",
        ")\n",
        "\n",
        "# Filtrar adultos con ventas \"Medio\" o \"Alto\"\n",
        "filtro_adultos_ventas_medias_altas = datos_totales[\n",
        "    (datos_totales['Grupo_Edad'] == 'Adulto') & \n",
        "    (datos_totales['Rango_Ventas'].isin(['Medio', 'Alto']))\n",
        "]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Datos combinados del Reto Final:\")\n",
        "print(datos_totales)\n",
        "\n",
        "print(\"\\nFiltro de Adultos con Ventas Medias o Altas:\")\n",
        "print(filtro_adultos_ventas_medias_altas)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datos combinados del Reto Final:\n   ID_Venta Producto  Monto  Edad Grupo_Edad Rango_Ventas\n0         1        A    500    56      Mayor        Medio\n1         2        B    300    46      Mayor         Bajo\n2         3        C    450    32     Adulto        Medio\n3         4        A    700    60      Mayor         Alto\n4         5        B    200    25      Joven         Bajo\n5         6        D    600    38     Adulto        Medio\n\nFiltro de Adultos con Ventas Medias o Altas:\n   ID_Venta Producto  Monto  Edad Grupo_Edad Rango_Ventas\n2         3        C    450    32     Adulto        Medio\n5         6        D    600    38     Adulto        Medio\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1738058145347
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ruta relativa del archivo\n",
        "file_path = 'Users/aurelio.sosa.netmind/Pandas/titanic.csv'\n",
        "\n",
        "# Obtener la ruta absoluta\n",
        "absolute_path = os.path.abspath(file_path)\n",
        "print(\"Ruta absoluta del archivo:\", absolute_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ruta absoluta del archivo: /mnt/batch/tasks/shared/LS_root/mounts/clusters/aurelio-parra/code/Users/aurelio.sosa.netmind/Users/aurelio.sosa.netmind/Pandas/titanic.csv\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1738059689833
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset del Titanic\n",
        "file_path = r'Users/aurelio.sosa.netmind/Pandas/titanic.csv'\n",
        "titanic_data = pd.read_csv(file_path)\n",
        "\n",
        "# Visualizar las primeras filas del dataset para entender su estructura\n",
        "titanic_data.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1738059998890
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta absoluta del archivo en tu entorno de Azure\n",
        "file_path = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/aurelio-parra/code/Users/aurelio.sosa.netmind/Users/aurelio.sosa.netmind/Pandas/titanic.csv'\n",
        "\n",
        "# Intentar cargar el archivo\n",
        "try:\n",
        "    titanic_data = pd.read_csv(file_path)\n",
        "    print(\"Archivo cargado correctamente. Primeras filas:\")\n",
        "    print(titanic_data.head())\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Asegúrate de que el archivo esté disponible en la ruta especificada.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Error: [Errno 2] No such file or directory: '/mnt/batch/tasks/shared/LS_root/mounts/clusters/aurelio-parra/code/Users/aurelio.sosa.netmind/Users/aurelio.sosa.netmind/Pandas/titanic.csv'\nAsegúrate de que el archivo esté disponible en la ruta especificada.\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1738060122550
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "es"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}